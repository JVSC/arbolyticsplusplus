# arbolyticsplusplus

# Arbolytics ++ - Guia de Execu√ß√£o

Este projeto utiliza Docker Compose para orquestrar uma stack completa de an√°lise de dados epidemiol√≥gicos com Elasticsearch, Kibana, Redis e aplica√ß√µes Flask/Celery.

## Pr√©-requisitos

- Docker (vers√£o 20.10 ou superior)
- Docker Compose (vers√£o 2.0 ou superior)
- Pelo menos 4GB de RAM dispon√≠vel para os containers

## Configura√ß√£o Inicial

### 1. Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes vari√°veis:

```bash
# Vers√£o do Elastic Stack
STACK_VERSION=8.11.0

# Senhas (ALTERE ESTAS SENHAS!)
ELASTIC_PASSWORD=your_elastic_password_here
KIBANA_PASSWORD=your_kibana_password_here
ARBOLYTICS_PASSWORD=your_arbolytics_password_here

# Configura√ß√µes do Cluster
CLUSTER_NAME=arbolytics-cluster
LICENSE=basic

# Portas
ES_PORT=9200
KIBANA_PORT=5601

# Limite de Mem√≥ria por Container
MEM_LIMIT=1073741824
```

### 2. Estrutura de Dados

Certifique-se de que os diret√≥rios de dados existem:

```bash
mkdir -p data/cnes data/sinan
```

## Execu√ß√£o

### Iniciar todos os servi√ßos

```bash
docker-compose up -d
```

### Verificar status dos containers

```bash
docker-compose ps
```

### Acompanhar logs

```bash
# Todos os servi√ßos
docker-compose logs -f

# Servi√ßo espec√≠fico
docker-compose logs -f flask
```

### Parar os servi√ßos

```bash
docker-compose down
```

### Parar e remover volumes (CUIDADO: apaga todos os dados)

```bash
docker-compose down -v
```

## Servi√ßos Dispon√≠veis

### API Flask
- **URL**: http://localhost:3000
- **Descri√ß√£o**: API principal do Arbolytics para an√°lise de dados epidemiol√≥gicos
- **Funcionalidades**:
  - Endpoints para an√°lise de dados SINAN
  - Integra√ß√£o com Elasticsearch
  - Processamento de dados CNES

### Frontend
- **URL**: http://localhost:5173
- **Descri√ß√£o**: Interface web do Arbolytics
- **Tecnologias**: Vue.js, Vite, Tailwind CSS

### Elasticsearch Cluster
- **URLs**: 
  - N√≥ 1: https://localhost:9200
  - N√≥s 2 e 3: Acesso interno apenas
- **Descri√ß√£o**: Cluster de 3 n√≥s para armazenamento e busca de dados
- **Credenciais**:
  - Usu√°rio: `elastic`
  - Senha: Definida em `ELASTIC_PASSWORD`
  - Usu√°rio app: `arbolytics` / Senha: `ARBOLYTICS_PASSWORD`

### Kibana
- **URL**: http://localhost:5601
- **Descri√ß√£o**: Interface de visualiza√ß√£o e an√°lise dos dados do Elasticsearch
- **Credenciais**:
  - Usu√°rio: `kibana_system`
  - Senha: Definida em `KIBANA_PASSWORD`

### Redis
- **Porta**: 6379 (acesso interno)
- **Descri√ß√£o**: Cache e broker de mensagens para Celery
- **Persist√™ncia**: Dados salvos em volume `redisdata`

### Celery Worker
- **Descri√ß√£o**: Processamento ass√≠ncrono de tarefas
- **Funcionalidades**:
  - Processamento de dados em background
  - C√°lculos estat√≠sticos
  - Agrega√ß√µes de dados

## Volumes Persistentes

- `esdata01`, `esdata02`, `esdata03`: Dados do Elasticsearch
- `kibanadata`: Configura√ß√µes e dashboards do Kibana
- `redisdata`: Cache do Redis
- `certs`: Certificados SSL do Elasticsearch
- `cache`: Cache geral da aplica√ß√£o

### Usu√°rios Criados Automaticamente
1. **elastic**: Usu√°rio superadmin do Elasticsearch
2. **kibana_system**: Usu√°rio para conex√£o Kibana-Elasticsearch  
3. **arbolytics**: Usu√°rio da aplica√ß√£o com privil√©gios de superuser

## √çndices Elasticsearch

O sistema cria automaticamente templates para os seguintes padr√µes:

- `sinan.*`: Dados do SINAN (Sistema de Informa√ß√£o de Agravos de Notifica√ß√£o)
- `cnes-*`: Dados do CNES (Cadastro Nacional de Estabelecimentos de Sa√∫de)
- `id-cnes-*`: Dados de identifica√ß√£o CNES
- `dados_*`: Dados gerais processados

## Desenvolvimento



## ü§ù Contribui√ß√£o

Para contribuir com o projeto:

1. Fork o reposit√≥rio
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo LICENSE para detalhes.
